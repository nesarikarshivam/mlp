
import numpy as np
import pandas as pd
import sklearn.metrics 
from sklearn.metrics import confusion_matrix

from sklearn.metrics import accuracy_score

from sklearn import preprocessing

from sklearn.model_selection import train_test_split

from sklearn.neural_network import MLPClassifier
import matplotlib.pyplot as plt
from sklearn import metrics
import itertools


data=pd.read_csv('/content/drive/MyDrive/Machine Learning - IS61/Lab/Multi Layer Perceptron/HR_comma_sep.csv')

data.shape
data.head()



le = preprocessing.LabelEncoder()

# Converting string labels into numbers.
data['Encoded Salary']=le.fit_transform(data['salary'])
data['Dept']=le.fit_transform(data['sales'])
# Displaying to see the transformation 
print(data[['Encoded Salary','Dept']])
data.sales.unique()
pd.unique(data[['sales', 'Dept']].values.ravel('K'))



X=data[['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', 
        'time_spend_company', 'Work_accident', 'promotion_last_5years', 'Dept', 'Encoded Salary']]

y=data['left']



# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) 



clf = MLPClassifier(hidden_layer_sizes=(6,5),
                    random_state=5,
                    verbose=False,
                    learning_rate_init=0.01)

# Fit data onto the model
clf.fit(X_train,y_train)
clf.loss_curve_
#X=data[['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', 
       # 'time_spend_company', 'Work_accident', 'promotion_last_5years', 'Dept', 'Encoded Salary']]
  
testX = [[0.37,0.32,2,188,3,0,0,7,0]]  #Employee will leave
#testX = [[0.77,0.72,2,159,3,0,0,2,2]]    #Employee will stay 
testpred=clf.predict(testX)
print("testpred is :", testpred)

if testpred == 0: 
  print("Employee will stay")
else:
  print("Employee will leave")


# Make prediction on train dataset
ypredtrain = clf.predict(X_train)

# Calcuate accuracy
print("Accuracy Score for Train Data is",accuracy_score(y_train,ypredtrain))

# Make prediction on test dataset
ypredtest=clf.predict(X_test)

# Calcuate accuracy
print("Accuracy Score for Test Data is", accuracy_score(y_test,ypredtest))


from sklearn.metrics import confusion_matrix
conftrain=confusion_matrix(y_train,ypredtrain)
print("Train Confusion Matrix is\n", conftrain)
 

TN, FN, FP, TP = metrics.confusion_matrix(list(y_test), list(ypredtest), labels=[0, 1]).ravel() #0,1 is default label of sklearn

print("\n For Test Data")
print("\nTH",TN)
print("\nTP",TP)
print("\nFH",FN)
print("\nFP",FP)


print("\n Test Precision is", metrics.precision_score(y_test, ypredtest))


print("\n Test Recall is", metrics.recall_score(y_test, ypredtest))


classes = [0, 1]

# plot train  confusion matrix
myplt=plt.figure(figsize=(8,8))
ax1 = myplt.add_subplot(2,2,1)

plt.imshow(conftrain, interpolation='nearest', cmap=plt.cm.Blues)
plt.title("Train Confusion Matrix")
ax1=plt.colorbar()
tick_marks = np.arange(len(classes))
plt.xticks(tick_marks, classes)
plt.yticks(tick_marks, classes)

fmt = 'd'
thresh = conftrain.max() / 2.
for i, j in itertools.product(range(conftrain.shape[0]), range(conftrain.shape[1])):
    plt.text(j, i, format(conftrain[i, j], fmt),
             horizontalalignment="center",
             color="white" if conftrain[i, j] > thresh else "black")

plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')

# plot test confusion matrix
ax2 = myplt.add_subplot(2,2,2)

plt.imshow(conftest, interpolation='nearest', cmap=plt.cm.Greens)
plt.title("Test Confusion Matrix")
ax2=plt.colorbar()
tick_marks = np.arange(len(classes))
plt.xticks(tick_marks, classes)
plt.yticks(tick_marks, classes)

fmt = 'd'
thresh = conftest.max() / 2.
for i, j in itertools.product(range(conftest.shape[0]), range(conftest.shape[1])):
    plt.text(j, i, format(conftest[i, j], fmt),
             horizontalalignment="center",
             color="white" if conftest[i, j] > thresh else "black")

plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')


N_TRAIN_SAMPLES = X_train.shape[0]
N_EPOCHS = 25
N_BATCH = 128
N_CLASSES = np.unique(y_train)

scores_train = []
scores_test = []

# EPOCH
epoch = 0
while epoch < N_EPOCHS:
    #print('epoch: ', epoch)
    # SHUFFLING
    # Do randon permutation umtil the # of rows in dataset. Here it is 14,999
    random_perm = np.random.permutation(X_train.shape[0])
    mini_batch_index = 0

    #Do mini-batch training until # of rows are reached 
    while True:
        # MINI-BATCH
        # Do for a random # of rows + fixed batch sixe 
        indices = random_perm[mini_batch_index:mini_batch_index + N_BATCH]
        # Fit the MLP Classifier 
        clf.partial_fit(X_train.iloc[indices], y_train.iloc[indices], classes=N_CLASSES)
        # Do for the rest after the previous mini-batch index 
        mini_batch_index += N_BATCH

        if mini_batch_index >= N_TRAIN_SAMPLES:
            break

    # ACCURACY SCORE FOR TRAIN
    scores_train.append(clf.score(X_train, y_train))

    # ACCURACY SCORE FOR TEST
    scores_test.append(clf.score(X_test, y_test))

    epoch += 1

""" Plotting the Accuracy Score Over the 25 Epochs"""
fig, ax = plt.subplots(2, sharex=True, sharey=True)
ax[0].plot(scores_train)
ax[0].set_title('Train')
ax[1].plot(scores_test)
ax[1].set_title('Test')
fig.suptitle("Accuracy over epochs", fontsize=14)
plt.show()
